{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1235,
   "id": "e1f5438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "id": "88a446c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([(\"i love spending time with my friends and family\", \"positive\"),\n",
    "                     (\"that was the best meal i've ever had in my life\", \"positive\"),\n",
    "                     (\"i feel so grateful for everything i have in my life\", \"positive\"),\n",
    "                     (\"i received a promotion at work and i couldn't be happier\", \"positive\"),\n",
    "                     (\"watching a beautiful sunset always fills me with joy\", \"positive\"),\n",
    "                     (\"my partner surprised me with a thoughtful gift and it made my day\", \"positive\"),\n",
    "                     (\"i am so proud of my daughter for graduating with honors\", \"positive\"),\n",
    "                     (\"listening to my favorite music always puts me in a good mood\", \"positive\"),\n",
    "                     (\"i love the feeling of accomplishment after completing a challenging task\", \"positive\"),\n",
    "                     (\"i am excited to go on vacation next week\", \"positive\"),\n",
    "                     (\"i feel so overwhelmed with work and responsibilities\", \"negative\"),\n",
    "                     (\"the traffic during my commute is always so frustrating\", \"negative\"),\n",
    "                     (\"i received a parking ticket and it ruined my day\", \"negative\"),\n",
    "                     (\"i got into an argument with my partner and we're not speaking\", \"negative\"),\n",
    "                     (\"i have a headache and i feel terrible\", \"negative\"),\n",
    "                     (\"i received a rejection letter for the job i really wanted\", \"negative\"),\n",
    "                     (\"my car broke down and it's going to be expensive to fix\", \"negative\"),\n",
    "                     (\"i'm feeling sad because i miss my friends who live far away\", \"negative\"),\n",
    "                     (\"i'm frustrated because i can't seem to make progress on my project\", \"negative\"),\n",
    "                     (\"i'm disappointed because my team lost the game\", \"negative\")\n",
    "                    ],\n",
    "                    columns=['text', 'sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "id": "82a92052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love spending time with my friends and family</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>that was the best meal i've ever had in my life</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel so grateful for everything i have in my...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i received a promotion at work and i couldn't ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watching a beautiful sunset always fills me wi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0    i love spending time with my friends and family  positive\n",
       "1    that was the best meal i've ever had in my life  positive\n",
       "2  i feel so grateful for everything i have in my...  positive\n",
       "3  i received a promotion at work and i couldn't ...  positive\n",
       "4  watching a beautiful sunset always fills me wi...  positive"
      ]
     },
     "execution_count": 1237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "id": "9a96cc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i got into an argument with my partner and we'...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm feeling sad because i miss my friends who ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i am so proud of my daughter for graduating wi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am excited to go on vacation next week</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i'm frustrated because i can't seem to make pr...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  i got into an argument with my partner and we'...  negative\n",
       "1  i'm feeling sad because i miss my friends who ...  negative\n",
       "2  i am so proud of my daughter for graduating wi...  positive\n",
       "3           i am excited to go on vacation next week  positive\n",
       "4  i'm frustrated because i can't seem to make pr...  negative"
      ]
     },
     "execution_count": 1238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SHUFFLE THE DATASET\n",
    "# `drop=True` - do not keep old index as a separate column.\n",
    "data = data.sample(frac = 1).reset_index(drop = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "id": "259d6645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE INPUTS\n",
    "col_text = data['text']\n",
    "col_sentiment = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1240,
   "id": "6c730883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.get of     accomplishment  after  always  am  an  and  argument  at  away  be  ...  \\\n",
       "0                0      0       0   0   1    1         1   0     0   0  ...   \n",
       "1                0      0       0   0   0    0         0   0     1   0  ...   \n",
       "2                0      0       0   1   0    0         0   0     0   0  ...   \n",
       "3                0      0       0   1   0    0         0   0     0   0  ...   \n",
       "4                0      0       0   0   0    0         0   0     0   0  ...   \n",
       "5                0      0       0   0   0    1         0   1     0   1  ...   \n",
       "6                1      1       0   0   0    0         0   0     0   0  ...   \n",
       "7                0      0       0   0   0    1         0   0     0   1  ...   \n",
       "8                0      0       0   0   0    0         0   0     0   0  ...   \n",
       "9                0      0       0   0   0    1         0   0     0   0  ...   \n",
       "10               0      0       1   0   0    0         0   0     0   0  ...   \n",
       "11               0      0       1   0   0    0         0   0     0   0  ...   \n",
       "12               0      0       0   0   0    1         0   0     0   0  ...   \n",
       "13               0      0       0   0   0    1         0   0     0   0  ...   \n",
       "14               0      0       1   0   0    0         0   0     0   0  ...   \n",
       "15               0      0       0   0   0    0         0   0     0   0  ...   \n",
       "16               0      0       0   0   0    0         0   0     0   0  ...   \n",
       "17               0      0       0   0   0    0         0   0     0   0  ...   \n",
       "18               0      0       0   0   0    1         0   0     0   0  ...   \n",
       "19               0      0       0   0   0    1         0   0     0   0  ...   \n",
       "\n",
       "    vacation  ve  wanted  was  watching  we  week  who  with  work  \n",
       "0          0   0       0    0         0   1     0    0     1     0  \n",
       "1          0   0       0    0         0   0     0    1     0     0  \n",
       "2          0   0       0    0         0   0     0    0     1     0  \n",
       "3          1   0       0    0         0   0     1    0     0     0  \n",
       "4          0   0       0    0         0   0     0    0     0     0  \n",
       "5          0   0       0    0         0   0     0    0     0     1  \n",
       "6          0   0       0    0         0   0     0    0     0     0  \n",
       "7          0   0       0    0         0   0     0    0     0     0  \n",
       "8          0   1       0    1         0   0     0    0     0     0  \n",
       "9          0   0       0    0         0   0     0    0     1     0  \n",
       "10         0   0       0    0         0   0     0    0     0     0  \n",
       "11         0   0       0    0         1   0     0    0     1     0  \n",
       "12         0   0       0    0         0   0     0    0     0     0  \n",
       "13         0   0       0    0         0   0     0    0     1     0  \n",
       "14         0   0       0    0         0   0     0    0     0     0  \n",
       "15         0   0       0    0         0   0     0    0     0     0  \n",
       "16         0   0       1    0         0   0     0    0     0     0  \n",
       "17         0   0       0    0         0   0     0    0     0     0  \n",
       "18         0   0       0    0         0   0     0    0     0     0  \n",
       "19         0   0       0    0         0   0     0    0     1     1  \n",
       "\n",
       "[20 rows x 118 columns]>"
      ]
     },
     "execution_count": 1240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEXT VECTORISATION (BAG OF WORDS)\n",
    "# Each word in the dataset is represented as a feature/column with `CountVectorizer`.\n",
    "countvec = CountVectorizer()\n",
    "countvec_fit = countvec.fit_transform(col_text)\n",
    "\n",
    "bag_of_words = pd.DataFrame(\n",
    "    countvec_fit.toarray(),\n",
    "    columns=countvec.get_feature_names_out()\n",
    ")\n",
    "\n",
    "bag_of_words.get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "id": "20ce5b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEY STEP: SPLIT DATA INTO TRAINING AND TEST SETS\n",
    "# Training set: used to train the model\n",
    "# Test set: used to evaluate the model\n",
    "\n",
    "text_train, text_test, sentiment_train, sentiment_test = train_test_split(\n",
    "    bag_of_words,\n",
    "    col_sentiment,\n",
    "    # 30% for testing (20-30% in practice), 70% for training\n",
    "    test_size=0.3,\n",
    "    # set a random state for reproducibility\n",
    "    random_state=7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b92676",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "id": "61b3a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `fit` means that we train the model\n",
    "lr = LogisticRegression(random_state=1).fit(text_train, sentiment_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "id": "320b8163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'negative' 'positive' 'negative' 'positive' 'positive']\n",
      "1     negative\n",
      "17    negative\n",
      "2     positive\n",
      "5     positive\n",
      "11    positive\n",
      "0     negative\n",
      "Name: sentiment, dtype: object\n"
     ]
    }
   ],
   "source": [
    "sentiment_pred_lr = lr.predict(text_test)\n",
    "print(sentiment_pred_lr)\n",
    "print(sentiment_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1244,
   "id": "a6ec2959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(sentiment_pred_lr, sentiment_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1245,
   "id": "367b430c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.20      1.00      0.33         1\n",
      "    positive       1.00      0.20      0.33         5\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.60      0.60      0.33         6\n",
      "weighted avg       0.87      0.33      0.33         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DETAILED CLASSIFICATION REPORT\n",
    "# It shows how the model performed for each class (precision, recall, F1-score)\n",
    "# F1-score is the harmonic mean of precision and recall\n",
    "# recall is the ability of the model to find all the relevant cases (true positives)\n",
    "# precision is the ability of the model to return only relevant cases\n",
    "print(classification_report(y_test, y_pred_lr, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a60d082",
   "metadata": {},
   "source": [
    "# Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1246,
   "id": "238b315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1247,
   "id": "eebfe9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model inputting the training data\n",
    "nb = MultinomialNB().fit(text_train, sentiment_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1248,
   "id": "9c87aec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'negative' 'positive' 'negative' 'positive' 'positive']\n"
     ]
    }
   ],
   "source": [
    "# Create predictions\n",
    "sentiment_pred_nb = nb.predict(text_test)\n",
    "print(sentiment_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "id": "22ee9ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "accuracy_nb = accuracy_score(sentiment_pred_nb, sentiment_test)\n",
    "print(f\"Naive Bayes Accuracy: {accuracy_nb:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c2c4e3",
   "metadata": {},
   "source": [
    "# Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "id": "e0b1870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1251,
   "id": "8e17309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model inputting the training data\n",
    "svm = SGDClassifier().fit(text_train, sentiment_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1252,
   "id": "75c174e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'positive' 'positive' 'negative' 'positive' 'positive']\n"
     ]
    }
   ],
   "source": [
    "sentiment_pred_svm = svm.predict(text_test)\n",
    "print(sentiment_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1253,
   "id": "c5d42d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.33\n"
     ]
    }
   ],
   "source": [
    "accuracy_svm = accuracy_score(sentiment_pred_svm, sentiment_test)\n",
    "print(f\"SVM Accuracy: {accuracy_svm:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1254,
   "id": "abdfc119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         3\n",
      "    positive       0.40      0.67      0.50         3\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.20      0.33      0.25         6\n",
      "weighted avg       0.20      0.33      0.25         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(sentiment_test, sentiment_pred_svm, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP course",
   "language": "python",
   "name": "nlp-course-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
